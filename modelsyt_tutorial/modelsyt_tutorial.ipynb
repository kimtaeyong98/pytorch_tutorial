{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\taeyong\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model:\n",
      "TinyModel(\n",
      "  (linear1): Linear(in_features=100, out_features=200, bias=True)\n",
      "  (activation): ReLU()\n",
      "  (linear2): Linear(in_features=200, out_features=10, bias=True)\n",
      "  (softmax): Softmax(dim=None)\n",
      ")\n",
      "\n",
      "\n",
      "Just one layer:\n",
      "Linear(in_features=200, out_features=10, bias=True)\n",
      "\n",
      "\n",
      "Model params:\n",
      "Parameter containing:\n",
      "tensor([[ 0.0522, -0.0493,  0.0462,  ..., -0.0590, -0.0924,  0.0640],\n",
      "        [-0.0518, -0.0091, -0.0404,  ...,  0.0819, -0.0570, -0.0736],\n",
      "        [ 0.0796,  0.0712,  0.0965,  ...,  0.0196,  0.0518,  0.0074],\n",
      "        ...,\n",
      "        [ 0.0774, -0.0157, -0.0623,  ...,  0.0767,  0.0325,  0.0910],\n",
      "        [ 0.0103,  0.0824, -0.0647,  ...,  0.0551,  0.0260, -0.0538],\n",
      "        [-0.0476, -0.0027, -0.0020,  ..., -0.0004, -0.0257,  0.0908]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0515,  0.0662,  0.0373, -0.0365,  0.0794, -0.0624, -0.0595,  0.0061,\n",
      "         0.0371, -0.0127, -0.0774, -0.0009,  0.0996, -0.0827,  0.0903, -0.0265,\n",
      "         0.0021,  0.0170,  0.0314, -0.0747,  0.0485,  0.0286,  0.0533,  0.0204,\n",
      "         0.0833, -0.0824,  0.0085, -0.0762,  0.0440,  0.0635,  0.0579, -0.0427,\n",
      "        -0.0899, -0.0393, -0.0491, -0.0279, -0.0075, -0.0294,  0.0509,  0.0692,\n",
      "         0.0547, -0.0474, -0.0402,  0.0911,  0.0865, -0.0717,  0.0047, -0.0852,\n",
      "         0.0836,  0.0107, -0.0100, -0.0659, -0.0664, -0.0519, -0.0266,  0.0163,\n",
      "        -0.0560,  0.0713, -0.0008,  0.0852, -0.0103,  0.0787,  0.0240,  0.0498,\n",
      "        -0.0262, -0.0308,  0.0148, -0.0320, -0.0681,  0.0060,  0.0639,  0.0871,\n",
      "        -0.0395, -0.0605,  0.0353,  0.0722, -0.0433,  0.0743,  0.0190,  0.0592,\n",
      "        -0.0335,  0.0551,  0.0723, -0.0764,  0.0484, -0.0040,  0.0850, -0.0810,\n",
      "         0.0765,  0.0689,  0.0908,  0.0784, -0.0063, -0.0399,  0.0820,  0.0554,\n",
      "        -0.0715,  0.0154,  0.0229,  0.0257, -0.0070, -0.0987, -0.0178, -0.0165,\n",
      "        -0.0618, -0.0463, -0.0096, -0.0018, -0.0831,  0.0866, -0.0855,  0.0580,\n",
      "        -0.0773,  0.0605,  0.0628, -0.0511,  0.0334, -0.0453,  0.0730,  0.0567,\n",
      "         0.0152,  0.0766, -0.0416,  0.0660,  0.0837,  0.0810,  0.0803,  0.0614,\n",
      "        -0.0846,  0.0594, -0.0775, -0.0508,  0.0406, -0.0256, -0.0515,  0.0626,\n",
      "        -0.0320, -0.0575, -0.0328,  0.0130, -0.0273, -0.0326,  0.0768,  0.0118,\n",
      "        -0.0400, -0.0036,  0.0750, -0.0228, -0.0908, -0.0228,  0.0141,  0.0845,\n",
      "        -0.0159,  0.0133, -0.0753,  0.0003, -0.0321,  0.0806, -0.0923, -0.0835,\n",
      "         0.0691, -0.0653, -0.0766,  0.0955,  0.0303,  0.0987, -0.0926,  0.0428,\n",
      "         0.0172,  0.0491, -0.0813,  0.0269,  0.0474,  0.0408,  0.0479,  0.0785,\n",
      "        -0.0891, -0.0164, -0.0135,  0.0554,  0.0463, -0.0119, -0.0675,  0.0133,\n",
      "        -0.0102,  0.0547,  0.0434, -0.0624, -0.0008,  0.0833, -0.0604, -0.0746,\n",
      "        -0.0209,  0.0564, -0.0900,  0.0499, -0.0721,  0.0479,  0.0947, -0.0540],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0605,  0.0514, -0.0522,  ..., -0.0675,  0.0359,  0.0432],\n",
      "        [ 0.0599,  0.0138, -0.0068,  ..., -0.0070,  0.0179,  0.0232],\n",
      "        [ 0.0588, -0.0181, -0.0031,  ...,  0.0570, -0.0056, -0.0221],\n",
      "        ...,\n",
      "        [ 0.0604, -0.0310,  0.0690,  ...,  0.0606, -0.0294, -0.0176],\n",
      "        [-0.0301, -0.0526, -0.0374,  ...,  0.0265,  0.0257, -0.0093],\n",
      "        [ 0.0561, -0.0279, -0.0613,  ..., -0.0474, -0.0492, -0.0054]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0112,  0.0464,  0.0138,  0.0424,  0.0317,  0.0072,  0.0396,  0.0373,\n",
      "        -0.0042,  0.0474], requires_grad=True)\n",
      "\n",
      "\n",
      "Layer params:\n",
      "Parameter containing:\n",
      "tensor([[-0.0605,  0.0514, -0.0522,  ..., -0.0675,  0.0359,  0.0432],\n",
      "        [ 0.0599,  0.0138, -0.0068,  ..., -0.0070,  0.0179,  0.0232],\n",
      "        [ 0.0588, -0.0181, -0.0031,  ...,  0.0570, -0.0056, -0.0221],\n",
      "        ...,\n",
      "        [ 0.0604, -0.0310,  0.0690,  ...,  0.0606, -0.0294, -0.0176],\n",
      "        [-0.0301, -0.0526, -0.0374,  ...,  0.0265,  0.0257, -0.0093],\n",
      "        [ 0.0561, -0.0279, -0.0613,  ..., -0.0474, -0.0492, -0.0054]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0112,  0.0464,  0.0138,  0.0424,  0.0317,  0.0072,  0.0396,  0.0373,\n",
      "        -0.0042,  0.0474], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "class TinyModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(TinyModel, self).__init__()\n",
    "\n",
    "        self.linear1 = torch.nn.Linear(100, 200)\n",
    "        self.activation = torch.nn.ReLU()\n",
    "        self.linear2 = torch.nn.Linear(200, 10)\n",
    "        self.softmax = torch.nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "tinymodel = TinyModel()\n",
    "\n",
    "print('The model:')\n",
    "print(tinymodel)\n",
    "\n",
    "print('\\n\\nJust one layer:')\n",
    "print(tinymodel.linear2)\n",
    "\n",
    "print('\\n\\nModel params:')\n",
    "for param in tinymodel.parameters():\n",
    "    print(param)\n",
    "\n",
    "print('\\n\\nLayer params:')\n",
    "for param in tinymodel.linear2.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "tensor([[0.7409, 0.0510, 0.5069]])\n",
      "\n",
      "\n",
      "Weight and Bias parameters:\n",
      "Parameter containing:\n",
      "tensor([[ 0.2551,  0.2945, -0.5053],\n",
      "        [ 0.5175, -0.2684,  0.2937]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.4646, -0.5663], requires_grad=True)\n",
      "\n",
      "\n",
      "Output:\n",
      "tensor([[-0.5167, -0.0477]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "lin = torch.nn.Linear(3, 2)\n",
    "x = torch.rand(1, 3)\n",
    "print('Input:')\n",
    "print(x)\n",
    "\n",
    "print('\\n\\nWeight and Bias parameters:')\n",
    "for param in lin.parameters():\n",
    "    print(param)\n",
    "\n",
    "y = lin(x)\n",
    "print('\\n\\nOutput:')\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.functional as F\n",
    "\n",
    "\n",
    "class LeNet(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        # 1 input image channel (black & white), 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = torch.nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = torch.nn.Conv2d(6, 16, 3)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = torch.nn.Linear(16 * 6 * 6, 120)  # 6*6 from image dimension\n",
    "        self.fc2 = torch.nn.Linear(120, 84)\n",
    "        self.fc3 = torch.nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTagger(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.word_embeddings = torch.nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = torch.nn.LSTM(embedding_dim, hidden_dim)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2tag = torch.nn.Linear(hidden_dim, tagset_size)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
    "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
    "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0805, 0.8823, 0.4568, 0.0808, 0.0249, 0.1826],\n",
      "         [0.7325, 0.9026, 0.9464, 0.5180, 0.0282, 0.1503],\n",
      "         [0.0733, 0.8582, 0.4195, 0.5514, 0.7293, 0.3175],\n",
      "         [0.6222, 0.9652, 0.6008, 0.2977, 0.7969, 0.6188],\n",
      "         [0.7303, 0.9731, 0.2464, 0.4661, 0.6103, 0.6005],\n",
      "         [0.5436, 0.3059, 0.9323, 0.1104, 0.8357, 0.9149]]])\n",
      "tensor([[[0.9464, 0.7293],\n",
      "         [0.9731, 0.9149]]])\n"
     ]
    }
   ],
   "source": [
    "my_tensor = torch.rand(1, 6, 6)\n",
    "print(my_tensor)\n",
    "\n",
    "maxpool_layer = torch.nn.MaxPool2d(3)\n",
    "print(maxpool_layer(my_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[14.6249, 17.8466, 14.9056, 11.0231],\n",
      "         [ 9.7153, 21.7817,  5.7081, 11.9020],\n",
      "         [19.5824, 20.7471, 18.0884,  8.6634],\n",
      "         [24.7661, 12.7220, 12.4863, 21.1029]]])\n",
      "tensor(15.3541)\n",
      "tensor([[[ 0.0103,  1.3415,  0.1263, -1.4780],\n",
      "         [-0.4327,  1.6055, -1.1095, -0.0633],\n",
      "         [ 0.5890,  0.8329,  0.2761, -1.6980],\n",
      "         [ 1.3138, -0.9477, -0.9920,  0.6259]]],\n",
      "       grad_fn=<NativeBatchNormBackward0>)\n",
      "tensor(-8.1956e-08, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "my_tensor = torch.rand(1, 4, 4) * 20 + 5\n",
    "print(my_tensor)\n",
    "\n",
    "print(my_tensor.mean())\n",
    "\n",
    "norm_layer = torch.nn.BatchNorm1d(4)\n",
    "normed_tensor = norm_layer(my_tensor)\n",
    "print(normed_tensor)\n",
    "\n",
    "print(normed_tensor.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0000, 0.0000, 0.4239, 0.0000],\n",
      "         [0.9084, 0.0000, 0.0000, 1.2953],\n",
      "         [0.0000, 0.0000, 0.5773, 0.6990],\n",
      "         [0.7434, 0.0000, 0.7578, 0.0000]]])\n",
      "tensor([[[0.0000, 1.6165, 0.0000, 0.0000],\n",
      "         [0.0000, 1.1606, 0.0000, 1.2953],\n",
      "         [0.9743, 0.0000, 0.5773, 0.0000],\n",
      "         [0.0000, 0.0000, 0.7578, 1.0485]]])\n"
     ]
    }
   ],
   "source": [
    "my_tensor = torch.rand(1, 4, 4)\n",
    "\n",
    "dropout = torch.nn.Dropout(p=0.4)\n",
    "print(dropout(my_tensor))\n",
    "print(dropout(my_tensor))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11c4cb31333e8aa59cbff2148c1763edacdfeefdbe5c2dd2a934b744b24310c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
